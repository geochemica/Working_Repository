---
title: "Module 7"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Module 7
install.packages("sciplot")

#Finding the Geometric Mean
x <- c(1,2,3,4,5,6,7,8,9,10,100,1000)
gm1 <- function(x) {
    prod(x)^(1/length(x))}
gm1(x)

gm2 <- function(x) {
    exp(mean(log(x)))
}
gm2(x)
#These two formulas should yield the same result

#adding negative numbers and a zero into the formula
x <- c(-1,2,3,-4,5,-6,7,8,9,-10,0,1000)
gm1 <- function(x, na.rm=TRUE) {
  exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
}
gm1(x)
#The addition of the na.rm=TRUE should make this applicable to more vectors than the original one provided

#Measures of Spread
x <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 25, 50, 100, 200, 1000)
ss1 <- function(x) {
    sum((x - mean(x))^2)
}
ss1(x)

ss2 <- function(x) {
    sum(x^2) - length(x) * mean(x)^2
}
ss2(x)

ss3 <- function(x) {
    sum(x^2) - (sum(x))^2/length(x)
}
ss3(x)

mean(x)
sum( (x - mean(x) )^2 )
#the above four formulas will all get to the sum of squares

#Population Variance which is the sum of squares above the population
pop_v <- function(x) {
    sum((x - mean(x))^2)/(length(x))
}
pop_v(x)

sample variance = estimator of the population variance = sum of squares / (n - 1)

sample_v <-function(x) {sum((x - mean(x))^2)/(length(x))}
sample_v(x)
var(x)
#both of these formula also yield the same result

#ASKING INTERESTING QUESTIONS
plot(c(0, 50), c(0, 15), type = "n", xlab = "Sample size", ylab = "Variance")
for (n in seq(5, 50, 5)) # samples of 5, 10, 15...
{
    for (i in 1:50) # 50 replicates
    {
        x <- rnorm(n, mean = 10, sd = 2)
        points(n, var(x))
    }
}
#Standard Deviation
pop_sd <- function(x) {
    sqrt(pop_v(x))
}
pop_sd(x)

sample_sd <- function(x) {
    sqrt(sample_v(x))
}
sample_sd(x)

sd(x)

#the above three formula should all yield the same result for standard deviation

#Using Measures of Spread
#Describing Uncertainity in Estimated Parameters
#SE mean = square root of the average sample variance
#SE mean = square root of (sample variance / number of observations)
#SE mean = (sample standard deviation) / square root of (number of observations)

SE1 <- function(x) {
    sqrt(sample_v(x)/length(x))
}
SE1(x)

SE2 <- function(x) {
    sqrt(var(x)/length(x))
}
SE2(x)

SE3 <-function(x) {var(x)/sqrt(length(x))}
SE3(x)
#what is the sample standard deviation?

library(sciplot)
se(x)

#Calculating Confidence Intervals Using Standard Errors
#qnorm(0.025, mean=0, sd=1) tells us the number of standard deviations away from the mean that correspond with up to 2.5% of of the normal distribution with mean=0 and sd=1. qnorm(0.975, mean=0, sd=1) tells us the number of standard deviations up to which 97.5% of observations should fall.

set.seed(1)
x <- rnorm(10000, 0, 1)
hist(x)
#do we need to download set.seed?
x <- seq(from = -4, to = 4, by = 0.01)
plot(x, dnorm(x), cex = 0.4)
plot(x, pnorm(x), cex = 0.4)
x <- seq(from = 0, to = 1, by = 0.01)
plot(qnorm(x), x, cex = 0.4)

x <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)
m <- mean(x)
n <- length(x)
v <- var(x)
s <- sd(x)
e <- sqrt(v/n)
upper <- mean(x) + qnorm(0.975, mean = 0, sd = 1) * se(x)
lower <- mean(x) + qnorm(0.025, mean = 0, sd = 1) * se(x)  # or lower <- mean(x) - qnorm(0.975)*se(x)
ci <- c(lower, upper)
ci

upper <- m + qnorm(0.975, mean = 0, sd = 1) * e
lower <- m + qnorm(0.025, mean = 0, sd = 1) * e  # or lower <- m - qnorm(0.975)*e
ci <- c(lower, upper)
ci

normalCI = function(x, CIlevel = 0.95) {
    upper = m + qnorm(1 - (1 - CIlevel)/2) * sqrt(var(x)/length(x))
    lower = m + qnorm((1 - CIlevel)/2) * sqrt(var(x)/length(x))
    ci <- c(lower, upper)
    return(ci)
}
normalCI(x, 0.95)  # call the function

#these are showing the upper and lower limits on the confidence internval

set <- NULL  # sets up a dummy variable to hold our 10000 simulations
n <- 15
for (i in 1:10000) {
    set[i] <- mean(sample(x, n, replace = TRUE))
}
quantile(set)
quantile(set, c(0.025, 0.975))

#How does the CI calculated this way, by simulation, compare to that calculated based on assuming a normal distribution?

#By using the simulation we are creating a a distribution using the original population by sampling via replacement over and over again. This means that instead of assuming for normality, we can estimate the true distribution of the population through the simulation of resampling. With my data, often the population is not normal because of error with the instrument measuring the sample or because of vastly different elemental composition due to mixing for something else. I suspect that many of my results statistical results come out weird because I have to assume for normality and then test as if the data is normal. 


#How does the width of the CI change with decreasing or increasing n (the number of observations drawn from your sample with replacement)? For example, if we set n at 5? At 50? At 500?
#As can be seen below, as the number of observations from the sample increases, the width of the confidence interval decreases. 
#SUPER IMPORTANT SIDE NOTE: BOOTSTRAPPING (?) DATA WILL NEITHER MAKE IT NORMAL NOR WILL IT ALWAYS BE BETTER THAN ASSUMING FOR NORMALITY

> quantile(set, c(0.025, 0.975))
 2.5% 97.5% 
  4.2  11.8 
  for N = 5
  difference: 7.6
> quantile(set, c(0.025, 0.975))
 2.5% 97.5% 
  5.8  10.2 
  for N = 15
  difference: 4.4
> quantile(set, c(0.025, 0.975))
  2.5%  97.5% 
  6.7995 9.2200 
  for N = 50
  difference: 2.4205
> quantile(set, c(0.025, 0.975))
 2.5% 97.5% 
  7.622 8.388 
  for N = 500
  difference:0.766

